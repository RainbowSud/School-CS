train_control <- trainControl(method = "cv",
number = 5)
model <- train(V8~.,
data = data_seed,
tuneGrid = expand.grid(k = 1:15),
trControl = train_control,
method = "knn")
print(model)
plot(model)
#Loading package
library(class)
#library(caret)
library(ggplot2)
#Import Data
data_seed <- read.delim("data_seed.dat", header = FALSE, sep ='\t')
#Training Error
# split data into train and test data
split <- sample.split(data_seed, SplitRatio = 0.7)
train_cl <- subset(data_seed, split == "TRUE")
test_cl <- subset(data_seed, split == "FALSE")
# Feature Scaling
train_scale <- scale(train_cl[, 1:7])
test_scale <- scale(test_cl[, 1:7])
k_values <- c(1,5,10,15)
accuracy_values <- sapply(k_values, function(k) {
classifier_knn <- knn(train = train_scale,
test = test_scale,
cl =  train_cl$V8,
k = k)
1 - mean(classifier_knn != test_cl$V8)
})
accuracy_data <- data.frame(K = k_values, Accuracy = accuracy_values)
ggplot(accuracy_data, aes(x = K, y = Accuracy)) +
geom_line(color = "lightblue", size = 1) +
geom_point(color = "lightgreen", size = 3) +
labs(title = "Training Error ",
x = "Number of Neighbors (K)",
y = "Accuracy") +
theme_minimal()
#Test Error
set.seed(454234536)
train_control <- trainControl(method = "cv",
number = 5)
model <- train(V8~.,
data = data_seed,
tuneGrid = expand.grid(k = 1:15),
trControl = train_control,
method = "knn")
print(model)
plot(model)
#Import Data
data_seed <- read.delim("data_seed.dat", header = FALSE, sep ='\t')
#Manually Splitting dataset
# split data into train and test data
split <- sample.split(data_seed, SplitRatio = 0.7)
train_cl <- subset(data_seed, split == "TRUE")
test_cl <- subset(data_seed, split == "FALSE")
# Feature Scaling
train_scale <- scale(train_cl[, 1:7])
test_scale <- scale(test_cl[, 1:7])
k_values <- 1:15
accuracy_values <- sapply(k_values, function(k) {
classifier_knn <- knn(train = train_scale,
test = test_scale,
cl =  train_cl$V8,
k = k)
1 - mean(classifier_knn != test_cl$V8)
})
accuracy_data <- data.frame(K = k_values, Accuracy = accuracy_values)
ggplot(accuracy_data, aes(x = K, y = Accuracy)) +
geom_line(color = "lightblue", size = 1) +
geom_point(color = "lightgreen", size = 3) +
labs(title = "Training Error ",
x = "Number of Neighbors (K)",
y = "Accuracy") +
theme_minimal()
#Loading package
library(class)
library(ggplot2)
#Import Data
data_seed <- read.delim("data_seed.dat", header = FALSE, sep ='\t')
#Manually Splitting dataset
# split data into train and test data
split <- sample.split(data_seed, SplitRatio = 0.7)
train_cl <- subset(data_seed, split == "TRUE")
test_cl <- subset(data_seed, split == "FALSE")
# Feature Scaling
train_scale <- scale(train_cl[, 1:7])
test_scale <- scale(test_cl[, 1:7])
k_values <- 1:15
accuracy_values <- sapply(k_values, function(k) {
classifier_knn <- knn(train = train_scale,
test = test_scale,
cl =  train_cl$V8,
k = k)
1 - mean(classifier_knn != test_cl$V8)
})
accuracy_data <- data.frame(K = k_values, Accuracy = accuracy_values)
ggplot(accuracy_data, aes(x = K, y = Accuracy)) +
geom_line(color = "lightblue", size = 1) +
geom_point(color = "lightgreen", size = 3) +
labs(title = "Accuarcy of guesses vased on K value",
x = "Number of Neighbors checked (K)",
y = "Accuracy") +
theme_minimal()
#Doing 5-fold CV and getting MSE
set.seed(454234536)
train_control <- trainControl(method = "cv",
number = 5)
model <- train(V8~.,
data = data_seed,
tuneGrid = expand.grid(k = 1:15),
trControl = train_control,
method = "knn")
print(model)
plot(model)
#Doing K-fold CV and getting MSE
set.seed(454234536)
KFoldKNN <- function(k) {
train_control <- trainControl(method = "cv",
number = k)
model <- train(V8~.,
data = data_seed,
tuneGrid = expand.grid(k = 1:15),
trControl = train_control,
method = "knn")
print(model)
plot(model)
}
KFoldNNN(5)
KFoldKNN(5)
KFoldKNN(10)
KFoldKNN(5)
KFoldKNN(10)
#Doing K-fold CV and getting MSE
set.seed(454234536)
KFoldKNN <- function(k) {
train_control <- trainControl(method = "cv",
number = k)
model <- train(V8~.,
data = data_seed,
tuneGrid = expand.grid(k = 1:100),
trControl = train_control,
method = "knn")
print(model)
plot(model)
}
KFoldKNN(5)
KFoldKNN(10)
#Manually Splitting dataset
# split data into train and test data
split <- sample.split(data_seed, SplitRatio = 0.7)
train_cl <- subset(data_seed, split == "TRUE")
test_cl <- subset(data_seed, split == "FALSE")
# Feature Scaling
train_scale <- scale(train_cl[, 1:7])
test_scale <- scale(test_cl[, 1:7])
k_values <- 1:100
accuracy_values <- sapply(k_values, function(k) {
classifier_knn <- knn(train = train_scale,
test = test_scale,
cl =  train_cl$V8,
k = k)
1 - mean(classifier_knn != test_cl$V8)
})
accuracy_data <- data.frame(K = k_values, Accuracy = accuracy_values)
ggplot(accuracy_data, aes(x = K, y = Accuracy)) +
geom_line(color = "lightblue", size = 1) +
geom_point(color = "lightgreen", size = 3) +
labs(title = "Accuarcy of guesses vased on K value",
x = "Number of Neighbors checked (K)",
y = "Accuracy") +
theme_minimal()
#Doing K-fold CV and getting MSE
set.seed(sample(1:1000000000,1))
KFoldKNN <- function(k) {
train_control <- trainControl(method = "cv",
number = k)
model <- train(V8~.,
data = data_seed,
tuneGrid = expand.grid(k = 1:100),
trControl = train_control,
method = "knn")
print(model)
plot(model)
}
KFoldKNN(5)
KFoldKNN(10)
KFoldKNN(5)
KFoldKNN <- function(k, kvalues) {
train_control <- trainControl(method = "cv",
number = k)
model <- train(V8~.,
data = data_seed,
tuneGrid = expand.grid(k = kvalues),
trControl = train_control,
method = "knn")
print(model)
plot(model)
}
KFoldKNN(5, 1:100)
KFoldKNN(10, 1:25)
Manual_Split_KNN <- function (Split_Ratio, K_Values) {
#Manually Splitting dataset
# split data into train and test data
split <- sample.split(data_seed, SplitRatio = 0.7)
train_cl <- subset(data_seed, split == "TRUE")
test_cl <- subset(data_seed, split == "FALSE")
# Feature Scaling
train_scale <- scale(train_cl[, 1:7])
test_scale <- scale(test_cl[, 1:7])
accuracy_values <- sapply(K_Values, function(k) {
classifier_knn <- knn(train = train_scale,
test = test_scale,
cl =  train_cl$V8,
k = k)
1 - mean(classifier_knn != test_cl$V8)
})
accuracy_data <- data.frame(K = k_values, Accuracy = accuracy_values)
ggplot(accuracy_data, aes(x = K, y = Accuracy)) +
geom_line(color = "lightblue", size = 1) +
geom_point(color = "lightgreen", size = 3) +
labs(title = "Accuracy of guesses based on K value",
x = "Number of Neighbors checked (K)",
y = "Accuracy") +
theme_minimal()
}
Manual_Split_KNN(0.7, 1:50)
Manual_Split_KNN(0.5, 1:50)
K_Fold_KNN(5, 1:100)
K_Fold_KNN <- function(Num_Folds, K_Values) {
set.seed(sample(1:1000000000,1))
train_control <- trainControl(method = "cv",
number = Num_Folds)
model <- train(V8~.,
data = data_seed,
tuneGrid = expand.grid(k = K_Values),
trControl = train_control,
method = "knn")
print(model)
plot(model)
}
K_Fold_KNN(5, 1:100)
K_Fold_KNN(5, 1:25)
K_Fold_KNN(10, 1:25)
Manual_Split_KNN(0.5, 1:25)
Manual_Split_KNN(0.7, 1:25)
K_Fold_KNN(5, 1:25)
K_Fold_KNN(10, 1:25)
Manual_Split_KNN(0.5, 1:25)
Manual_Split_KNN(0.7, 1:25)
Manual_Split_KNN(0.7, 1:25)
Manual_Split_KNN <- function (Split_Ratio, K_Values) {
#Manually Splitting dataset
# split data into train and test data
split <- sample.split(data_seed, SplitRatio = 0.7)
train_cl <- subset(data_seed, split == "TRUE")
test_cl <- subset(data_seed, split == "FALSE")
# Feature Scaling
train_scale <- scale(train_cl[, 1:7])
test_scale <- scale(test_cl[, 1:7])
accuracy_values <- sapply(K_Values, function(k) {
classifier_knn <- knn(train = train_scale,
test = test_scale,
cl =  train_cl$V8,
k = k)
1 - mean(classifier_knn != test_cl$V8)
})
accuracy_data <- data.frame(K = k_values, Accuracy = accuracy_values)
ggplot(accuracy_data, aes(x = K, y = Accuracy)) +
geom_line(color = "lightblue", size = 1) +
geom_point(color = "lightgreen", size = 3) +
labs(title = "Accuracy of guesses based on K value",
x = "Number of Neighbors checked (K)",
y = "Accuracy") +
theme_minimal()
}
K_Fold_KNN <- function(Num_Folds, K_Values) {
set.seed(sample(1:1000000000,1))
train_control <- trainControl(method = "cv",
number = Num_Folds)
model <- train(V8~.,
data = data_seed,
tuneGrid = expand.grid(k = K_Values),
trControl = train_control,
method = "knn")
print(model)
plot(model)
}
Manual_Split_KNN(0.5, 1:25)
Manual_Split_KNN(0.7, 1:25)
#Loading package
library(class)
library(ggplot2)
#Import Data
data_seed <- read.delim("data_seed.dat", header = FALSE, sep ='\t')
Manual_Split_KNN <- function (Split_Ratio, K_Values) {
#Manually Splitting dataset
# split data into train and test data
split <- sample.split(data_seed, SplitRatio = 0.7)
train_cl <- subset(data_seed, split == "TRUE")
test_cl <- subset(data_seed, split == "FALSE")
# Feature Scaling
train_scale <- scale(train_cl[, 1:7])
test_scale <- scale(test_cl[, 1:7])
accuracy_values <- sapply(K_Values, function(k) {
classifier_knn <- knn(train = train_scale,
test = test_scale,
cl =  train_cl$V8,
k = k)
1 - mean(classifier_knn != test_cl$V8)
})
accuracy_data <- data.frame(K = k_values, Accuracy = accuracy_values)
ggplot(accuracy_data, aes(x = K, y = Accuracy)) +
geom_line(color = "lightblue", size = 1) +
geom_point(color = "lightgreen", size = 3) +
labs(title = "Accuracy of guesses based on K value",
x = "Number of Neighbors checked (K)",
y = "Accuracy") +
theme_minimal()
}
K_Fold_KNN <- function(Num_Folds, K_Values) {
set.seed(sample(1:1000000000,1))
train_control <- trainControl(method = "cv",
number = Num_Folds)
model <- train(V8~.,
data = data_seed,
tuneGrid = expand.grid(k = K_Values),
trControl = train_control,
method = "knn")
print(model)
plot(model)
}
K_Fold_KNN(5, 1:25)
K_Fold_KNN(10, 1:25)
Manual_Split_KNN(0.5, 1:25)
Manual_Split_KNN <- function (Split_Ratio, K_Values) {
#Manually Splitting dataset
# split data into train and test data
split <- sample.split(data_seed, SplitRatio = 0.7)
train_cl <- subset(data_seed, split == "TRUE")
test_cl <- subset(data_seed, split == "FALSE")
# Feature Scaling
train_scale <- scale(train_cl[, 1:7])
test_scale <- scale(test_cl[, 1:7])
accuracy_values <- sapply(K_Values, function(k) {
classifier_knn <- knn(train = train_scale,
test = test_scale,
cl =  train_cl$V8,
k = k)
1 - mean(classifier_knn != test_cl$V8)
})
accuracy_data <- data.frame(K = K_Values, Accuracy = accuracy_values)
ggplot(accuracy_data, aes(x = K, y = Accuracy)) +
geom_line(color = "lightblue", size = 1) +
geom_point(color = "lightgreen", size = 3) +
labs(title = "Accuracy of guesses based on K value",
x = "Number of Neighbors checked (K)",
y = "Accuracy") +
theme_minimal()
}
K_Fold_KNN <- function(Num_Folds, K_Values) {
set.seed(sample(1:1000000000,1))
train_control <- trainControl(method = "cv",
number = Num_Folds)
model <- train(V8~.,
data = data_seed,
tuneGrid = expand.grid(k = K_Values),
trControl = train_control,
method = "knn")
print(model)
plot(model)
}
K_Fold_KNN(5, 1:25)
K_Fold_KNN(10, 1:25)
Manual_Split_KNN(0.5, 1:25)
Manual_Split_KNN(0.7, 1:25)
K_Fold_KNN(5, 1:50)
K_Fold_KNN(10, 1:50)
Manual_Split_KNN(0.5, 1:50)
Manual_Split_KNN(0.7, 1:50)
Manual_Split_KNN <- function (split_ratio, k_values) {
#Manually Splitting dataset
# split data into train and test data
split <- sample.split(data_seed, SplitRatio = split_ratio)
train_cl <- subset(data_seed, split == "TRUE")
test_cl <- subset(data_seed, split == "FALSE")
# Feature Scaling
train_scale <- scale(train_cl[, 1:7])
test_scale <- scale(test_cl[, 1:7])
accuracy_values <- sapply(k_values, function(k) {
classifier_knn <- knn(train = train_scale,
test = test_scale,
cl =  train_cl$V8,
k = k)
1 - mean(classifier_knn != test_cl$V8)
})
accuracy_data <- data.frame(K = k_values, Accuracy = accuracy_values)
ggplot(accuracy_data, aes(x = K, y = Accuracy)) +
geom_line(color = "lightblue", size = 1) +
geom_point(color = "lightgreen", size = 3) +
labs(title = "Accuracy of guesses based on K value",
x = "Number of Neighbors checked (K)",
y = "Accuracy") +
theme_minimal()
}
K_Fold_KNN <- function(num_folds, k_values) {
set.seed(sample(1:1000000000,1))
train_control <- trainControl(method = "cv",
number = num_folds)
model <- train(V8~.,
data = data_seed,
tuneGrid = expand.grid(k = k_values),
trControl = train_control,
method = "knn")
print(model)
plot(model)
}
K_Fold_KNN(5, 1:50)
K_Fold_KNN(10, 1:50)
Manual_Split_KNN(0.5, 1:50)
Manual_Split_KNN(0.7, 1:50)
Manual_Split_KNN <- function (split_ratio, k_values) {
#Manually Splitting dataset
# split data into train and test data
split <- sample.split(data_seed, SplitRatio = split_ratio)
train_cl <- subset(data_seed, split == "TRUE")
test_cl <- subset(data_seed, split == "FALSE")
# Feature Scaling
train_scale <- scale(train_cl[, 1:7])
test_scale <- scale(test_cl[, 1:7])
accuracy_values <- sapply(k_values, function(k) {
classifier_knn <- knn(train = train_scale,
test = test_scale,
cl =  train_cl$V8,
k = k)
1 - mean(classifier_knn != test_cl$V8)
})
accuracy_data <- data.frame(K = k_values, Accuracy = accuracy_values)
ggplot(accuracy_data, aes(x = K, y = Accuracy)) +
geom_line(color = "lightblue", size = 1) +
geom_point(color = "lightgreen", size = 3) +
labs(title = "Accuracy of guesses based on K value",
x = "Number of Neighbors checked (K)",
y = "Accuracy") +
theme_minimal()
}
K_Fold_KNN <- function(num_folds, k_values) {
set.seed(sample(1:1000000000,1))
train_control <- trainControl(method = "cv",
number = num_folds)
model <- train(V8~.,
data = data_seed,
tuneGrid = expand.grid(k = k_values),
trControl = train_control,
method = "knn")
print(model)
plot(model)
}
K_Fold_KNN(5, 1:50)
K_Fold_KNN <- function(num_folds, k_values) {
set.seed(sample(1:1000000000,1))
train_control <- trainControl(method = "cv",
number = num_folds)
model <- train(V8~.,
data = data_seed,
tuneGrid = expand.grid(k = k_values),
trControl = train_control,
method = "knn")
plot(model, main = "K-Fold-CV")
}
K_Fold_KNN(5, 1:50)
Manual_Split_KNN(0.7, 1:50)
K_Fold_KNN(5, 1:50)
Manual_Split_KNN(0.7, 1:50)
Manual_Split_KNN <- function (split_ratio, k_values) {
#Split data into train and test data
split <- sample.split(data_seed, SplitRatio = split_ratio)
train_set <- subset(data_seed, split == "TRUE")
test_set <- subset(data_seed, split == "FALSE")
train_values <- scale(train_set[, 1:7])
test_values <- scale(test_set[, 1:7])
results <- sapply(k_values, function(k) {
classifier_knn <- knn(train = train_values,
test = test_values,
cl =  train_set$V8,
k = k)
1 - mean(classifier_knn != test_set$V8)
})
result_df <- data.frame(K = k_values, Results = results)
ggplot(result_df, aes(x = K, y = Results)) +
geom_line(color = "gray", size = 1) +
geom_point(color = "black", size = 2) +
labs(title = "Accuracy of guesses based on K value",
x = "Number of Neighbors checked (K)",
y = "Accuracy") +
theme_minimal()
}
K_Fold_KNN <- function(num_folds, k_values) {
set.seed(sample(1:1000000000,1))
train_control <- trainControl(method = "cv",
number = num_folds)
model <- train(V8~.,
data = data_seed,
tuneGrid = expand.grid(k = k_values),
trControl = train_control,
method = "knn")
plot(model, main = "K-Fold-CV")
}
K_Fold_KNN(5, 1:50)
Manual_Split_KNN(0.7, 1:50)
K_Fold_KNN(5, 1:50)
